{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this code is to generate a large number of simulated ideal Faraday thin sources, add random noise, and run them through RM-tools, to see if the errors generated are reasonable.\n",
    "\n",
    "For this purpose, the free parameters in the simulation will be: -RM  -initial angle  -S:N  \n",
    "I'm not going to bother simulating spectral index or fractional polarization for now, since they won't affect things in a very interesting way (and will complicate the problem of defining S:N).  \n",
    "I am going to define the flux scale such that noise (per channel) = 1., and scale things relative to that.\n",
    "\n",
    "Random RMs: [-1000,1000]  \n",
    "Random angles: [0,180)  \n",
    "Random S:N per channel: [0.001,1000] (log-uniform?)\n",
    "\n",
    "I can simplify things by creating a 2D array of polarization spectra, since Cormac's code can handle 2D and 3D inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default preamble\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.close('all')\n",
    "plt.rcParams['figure.figsize'] = [16, 8]\n",
    "params = {'backend': 'pdf',\n",
    "          'axes.labelsize': 12,\n",
    "          'xtick.labelsize': 10,\n",
    "          'ytick.labelsize': 10,\n",
    "          #'legend.pad': 0.1,     # empty space around the legend box\n",
    "          'legend.fontsize': 18,\n",
    "          'lines.markersize': 7,\n",
    "          'font.size': 14,\n",
    "          'text.usetex': False}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/cvaneck/Projects/my_tools/') # why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from function_file import rm_sim.py as sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: '/Users/cvaneck/Projects/CIRADA_POL/POSSUM_SG5_simulation/'\n",
      "C:\\Users\\afine\\surp2020\\CTA200_project\n"
     ]
    }
   ],
   "source": [
    "cd \\Users\\afine\\surp2020\\CTA200_project # why also?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for the sim\n",
    "\n",
    "# ban = sim.bandwidth(f)\n",
    "# p_tilda = sim.bandwidth_avg_array(f, ban, phi, xi_knot, p)\n",
    "# size_f = len(f)\n",
    "# returns p_tilda array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Faraday_thin_complex_polarization(freq_array,RM,Polint,initial_angle):  # this is where i plug in the simulation?\n",
    "    \"\"\"freq_array = channel frequencies in Hz\n",
    "       RM = source RM in rad m^-2\n",
    "       Polint = polarized intensity in whatever units\n",
    "       initial angle = pre-rotation polarization angle (in degrees)\"\"\"\n",
    "    l2_array=(299792458./freq_array)**2\n",
    "    Q=Polint*np.cos(2*(np.outer(l2_array,RM)+np.deg2rad(initial_angle)))\n",
    "    U=Polint*np.sin(2*(np.outer(l2_array,RM)+np.deg2rad(initial_angle)))\n",
    "    return np.transpose(Q+1j*U)\n",
    "\n",
    "# def apply_spectral_index(freq_array, ref_flux, ref_frequency,spectral_index):\n",
    "#     return (freq_array/ref_frequency)**spectral_index*ref_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following Jennifer's example, the bandwidth is 700-1800 MHz, in 1 MHz channels\n",
    "freq_array=np.arange(700e6,1.8e9+1,1e6,dtype='float64')  \n",
    "l2_array=(299792458./freq_array)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation inputs:\n",
    "num_sources=1000  #number of sources to simulate\n",
    "#Q_arr=np.zeros([num_sources,freq_array.size])\n",
    "#U_arr=np.zeros_like(Q_arr)\n",
    "#I_arr=np.ones_like(Q_arr)\n",
    "dQ_arr=np.ones(freq_array.size) #need\n",
    "dU_arr=np.ones_like(dQ_arr) # need\n",
    "#dI_arr=np.ones_like(dQ_arr)\n",
    "RM_arr=np.random.uniform(-100,100,num_sources) # need\n",
    "angle_arr=np.random.uniform(0,180,num_sources) # xi_knot = inital angle, \n",
    "#PI_arr=10**np.random.uniform(0,3,num_sources)  # whats this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_perfect=Faraday_thin_complex_polarization(freq_array,RM_arr,PI_arr,angle_arr) # add a for loop to run the sim i times?\n",
    "Q_arr=np.real(sim_perfect)+np.random.normal(size=Q_arr.shape)\n",
    "U_arr=np.imag(sim_perfect)+np.random.normal(size=Q_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/cvaneck/Projects/CIRADA_POL/polarimetry/src/algorithms/') #what path to use? i dont have this\n",
    "#from RMutils.util_RM import do_rmsynth_planes,get_rmsf_planes\n",
    "from RMtools_1D.do_RMsynth_1D import run_rmsynth\n",
    "from RMutils.util_misc import progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_output=np.zeros(num_sources,dtype='f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8')\n",
    "catalog_output.dtype.names=('ID','phiPeakPIchan_rm2','dPhiPeakPIchan_rm2','ampPeakPIchanEff','dAmpPeakPIchan',\n",
    "                           'phiPeakPIfit_rm2','dPhiPeakPIfit_rm2','ampPeakPIfitEff','dAmpPeakPIfit','Ifreq0',\n",
    "                            'freq0_Hz','polAngle0Fit_deg','dPolAngle0Chan_deg','dPolAngle0Fit_deg','sigmaAddQ','sigmaAddU','dSigmaAddQ','dSigmaAddU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,"
     ]
    }
   ],
   "source": [
    "for i in range(num_sources):\n",
    "#(freqArr_Hz, IArr_Jy, QArr_Jy, UArr_Jy, dIArr_Jy, dQArr_Jy, dUArr_Jy) = data\n",
    "    input_data=(freq_array,I_arr[i],Q_arr[i],U_arr[i],dI_arr,dQ_arr,dU_arr) # array of arrays\n",
    "\n",
    "    mDict,aDict=run_rmsynth(input_data,  phiMax_radm2=200, dPhi_radm2=1., \n",
    "                nSamples=10.0, weightType=\"variance\", fitRMSF=False,\n",
    "                noStokesI=False, phiNoise_radm2=1e6, nBits=32, showPlots=False,   # should repeat this step 4 times for each?\n",
    "                  debug=False, verbose=False)\n",
    "    catalog_output[i]['ID']=i\n",
    "    for j in range(1,16):\n",
    "        catalog_output[i][catalog_output.dtype.names[j]]=mDict[catalog_output.dtype.names[j]]\n",
    "    try:\n",
    "        catalog_output[i]['dSigmaAddQ']=(mDict['dSigmaAddMinusQ']+mDict['dSigmaAddPlusQ'])/2.\n",
    "        catalog_output[i]['dSigmaAddU']=(mDict['dSigmaAddMinusU']+mDict['dSigmaAddPlusU'])/2.\n",
    "    except:\n",
    "        pass\n",
    "    if i%10 == 0:\n",
    "        print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('50k_sim.npy',(catalog_output,RM_arr,angle_arr,PI_arr))\n",
    "np.save('1k_sim.npy',(catalog_output,RM_arr,angle_arr,PI_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(catalog_output,RM_arr,angle_arr,PI_arr)=np.load('1k_sim.npy')\n",
    "catalog_output=np.array([x for x in catalog_output ])\n",
    "RM_arr=RM_arr.astype('float')\n",
    "angle_arr=angle_arr.astype('float')\n",
    "PI_arr=PI_arr.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SN_bin1=(PI_arr < 0.01)\n",
    "print('Bin 1 = {:} sources'.format(SN_bin1.sum()))\n",
    "SN_bin2=np.logical_and(PI_arr >= 0.01, PI_arr < 0.1)\n",
    "print('Bin 2 = {:} sources'.format(SN_bin2.sum()))\n",
    "SN_bin3=np.logical_and(PI_arr >= 0.1, PI_arr < 1.)\n",
    "print('Bin 3 = {:} sources'.format(SN_bin3.sum()))\n",
    "SN_bin4=np.logical_and(PI_arr >= 1., PI_arr < 10.)\n",
    "print('Bin 4 = {:} sources'.format(SN_bin4.sum()))\n",
    "SN_bin5=np.logical_and(PI_arr >= 10., PI_arr < 100.)\n",
    "print('Bin 5 = {:} sources'.format(SN_bin5.sum()))\n",
    "SN_bin6=PI_arr >= 100.\n",
    "print('Bin 6 = {:} sources'.format(SN_bin6.sum()))\n",
    "SN_threshold=(PI_arr > 0.3)  #This is the threshold for no false peak detections, based on a plot below.\n",
    "print(SN_threshold.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(PI_arr*np.sqrt(1101),np.abs(catalog_output[:,5]-RM_arr),'ko')\n",
    "plt.xlabel('Band-averaged S:N')\n",
    "plt.ylabel('FD residual (fit) (measured - actual) (rad m$^{-2}$)')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(5,label='5 sigma',linewidth=2)\n",
    "plt.plot(PI_arr*np.sqrt(1101),mDict['fwhmRMSF']/(2*PI_arr*np.sqrt(1101)),'r-',label='Classic error equation',linewidth=2)\n",
    "plt.plot(PI_arr*np.sqrt(1101),np.sqrt(mDict['fwhmRMSF']*1.)/(1.445*PI_arr*np.sqrt(1101)),'g--',label='Landsman82 equation',linewidth=2)\n",
    "plt.legend()\n",
    "plt.savefig('RM_error2.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr*np.sqrt(1101),np.abs(catalog_output[:,1]-RM_arr),'ko')\n",
    "plt.xlabel('Band-averaged S:N')\n",
    "plt.ylabel('FD residual (channel) (measured - actual) (rad m$^{-2}$)')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(5,label='5 sigma',linewidth=2)\n",
    "plt.plot(PI_arr*np.sqrt(1101),mDict['fwhmRMSF']/(2*PI_arr*np.sqrt(1101)),'r-',label='Classic error equation',linewidth=2)\n",
    "plt.plot(PI_arr*np.sqrt(1101),np.sqrt(mDict['fwhmRMSF']*1.)/(1.445*PI_arr*np.sqrt(1101)),'g--',label='Landsman82 equation',linewidth=2)\n",
    "plt.legend()\n",
    "plt.savefig('RM_error1.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows clearly the threshold at which source peaks are no longer being unambiguously identified. The threshold is roughly 0.2 S:N per channel, or roughly 6.6 sigma. Pretty much what's expected. I've set a threshold of 0.3 S:N per channel for the following analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],(catalog_output[SN_threshold]['phiPeakPIfit_rm2']-RM_arr[SN_threshold])/catalog_output[SN_threshold]['dPhiPeakPIchan_rm2'],'ko')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Scaled RM errror (measured - actual) (sigma)')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fascinating result. For moderate signal-to-noise values, the standard formula works great. But it underestimates the errors at high S:N, which is not surprising. The standard formula seems to work well for S:N per channel up to about 30 or so, or integrated S:N of about 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIchan_rm2'],'ko',label='chan_error')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Sigma_chan')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot confirms that the channel error follows the expected formula (with some minor deviations at the low S:N end, while the fit error is just a mirror to this with a slightly smaller number (and more scatter somehow?).\n",
    "\n",
    "I want to analyze this in two stages: first, using the intermediate S:N regime to verify that the errors are reasonable and check if any multiplicative correction factor is needed. Second, using the intermediate and high S:N cases to see if an additional error term can be derived that accurately reflects the observed behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_intermediate=np.logical_and(PI_arr >= 0.3, PI_arr < 30.)\n",
    "print('Intermediate S:N = {:} sources'.format(SN_intermediate.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "values,bins,patches=plt.hist((catalog_output[SN_intermediate,5]-RM_arr[SN_intermediate])/catalog_output[SN_intermediate,2]/1.10,bins=50,label='Measured')\n",
    "bin_centers=(bins[:-1]+bins[1:])/2.\n",
    "xlim=plt.gca().get_xlim()\n",
    "xarr=np.linspace(*xlim,100)\n",
    "from scipy.special import erf\n",
    "yarr=np.diff(erf(bins/np.sqrt(2)))*np.sum(values)/2.\n",
    "#plt.plot(xarr,np.sum(values)/np.sqrt(2*np.pi)*np.exp((xarr)**2/(-2.)),'k-')\n",
    "plt.plot(bin_centers,yarr,'ko-',label='Ideal')  #Predicted bin contents\n",
    "plt.legend()\n",
    "plt.title('Distribution of fit residuals (normalized by channel error)')\n",
    "plt.xlabel('($\\phi_{fit} - \\phi_{sim}) / \\sigma_{\\phi,chan}$')\n",
    "#plt.yscale('log')\n",
    "#plt.savefig('RM_distribution.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is slightly wider than expected. Some playing around suggests a correction factor of about 1.1 or slightly higher, by eye about 1.13Â±0.05. I can probably do a specific fit to the CDF to get a more precise value if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbins=200\n",
    "correction=1.10 #Correction factor on classical error.\n",
    "xbins=np.logspace(np.log10(0.3),3,Nbins+1)\n",
    "xbin_centers=(xbins[:-1]+xbins[1:])/2.\n",
    "std_residual=np.zeros(Nbins)\n",
    "std_residual_error=np.zeros(Nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Nbins):\n",
    "    srcs=np.where(np.logical_and(PI_arr >= xbins[i],PI_arr < xbins[i+1]))[0]\n",
    "    std_residual[i]=np.std(catalog_output[srcs]['phiPeakPIfit_rm2']-RM_arr[srcs])\n",
    "    std_residual_error[i]=std_residual[i]/np.sqrt(2*srcs.size-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(xbin_centers,std_residual,'ko',label='Simulation')\n",
    "plt.errorbar(xbin_centers,std_residual,yerr=std_residual_error,fmt='ko')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('S:N per channel')\n",
    "plt.ylabel('Stdev. RM residual')\n",
    "plt.plot(xbin_centers,correction*22.25/2./np.sqrt(1101)/xbin_centers,label='Classic formula with multiplier')\n",
    "plt.plot(xbin_centers,np.repeat(0.014,xbin_centers.shape),label='Constant error')\n",
    "plt.plot(xbin_centers,np.sqrt((correction*22.25/2./np.sqrt(1101)/xbin_centers)**2+np.repeat(0.014,xbin_centers.shape)**2),label='Quadrature sum')\n",
    "plt.plot(xbin_centers,(correction*22.25/2./np.sqrt(1101)/xbin_centers)+np.repeat(0.014,xbin_centers.shape),'g--',label='Linear sum')\n",
    "plt.ylim([0.01,2])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot is amazing: clearly, there is a minimum uncertainty that can't be overcome regardless of S:N. This uncertainty is independent of the statistical (S:N-based) uncertainty, so it needs to be added in quadrature.\n",
    "\n",
    "It might be worth doing a fit with two parameters, the constant and the multiplicative correction factor, to see how close to 1 the correction is, and to see if I can optimize the constant.\n",
    "\n",
    "The next question, which is important: on what factors does this constant depend? Does it change with delta-Phi? With RMSF-FWHM? With Nchan?\n",
    "\n",
    "## A fitting algorithm to determine the constant (and, possibly, correction factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhm=22.25\n",
    "nchan=1101\n",
    "from scipy.optimize import curve_fit\n",
    "def sigma_RM(SN,constant,correction):\n",
    "    return np.sqrt((correction*fwhm/2./np.sqrt(nchan)/SN)**2+constant**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt,pcov=curve_fit(sigma_RM,xbin_centers,std_residual,p0=[0.015,1.15],sigma=std_residual_error,absolute_sigma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(popt)\n",
    "print(np.sqrt(np.diag(pcov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up code for independent sims. I'm going to have one set of code with hard-coded variables, save the results, and then I can read them all in later.\n",
    "\n",
    "I'm also going to tighten the simulation parameters to target the key S:N range. I want to know: A) how the constant scales with certain parameters. B) if the correction factor scales with those same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation inputs:\n",
    "num_sources=1000  #sqrt of number of sources to simulate\n",
    "freq_array=np.arange(700e6,1.8e9+1,1e6,dtype='float64') #Following Jennifer's example, the bandwidth is 700-1800 MHz, in 1 MHz channels \n",
    "l2_array=(299792458./freq_array)**2\n",
    "Q_arr=np.zeros([num_sources,freq_array.size])\n",
    "U_arr=np.zeros_like(Q_arr)\n",
    "I_arr=np.ones_like(Q_arr)\n",
    "dQ_arr=np.ones(freq_array.size)\n",
    "dU_arr=np.ones_like(dQ_arr)\n",
    "dI_arr=np.ones_like(dQ_arr)\n",
    "RM_arr=np.random.uniform(-1000,1000,num_sources)\n",
    "angle_arr=np.random.uniform(0,180,num_sources)\n",
    "PI_arr=10**np.random.uniform(0,3,num_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_perfect=Faraday_thin_complex_polarization(freq_array,RM_arr,PI_arr,angle_arr)\n",
    "Q_arr=np.real(sim_perfect)+np.random.normal(size=Q_arr.shape)\n",
    "U_arr=np.imag(sim_perfect)+np.random.normal(size=Q_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/cvaneck/Projects/CIRADA_POL/polarimetry/src/algorithms/')\n",
    "#from RMutils.util_RM import do_rmsynth_planes,get_rmsf_planes\n",
    "from RMtools_1D.cl_RMsynth_1d import run_rmsynth\n",
    "from RMutils.util_misc import progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_output=np.zeros(num_sources,dtype='f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8')\n",
    "catalog_output.dtype.names=('ID','phiPeakPIchan_rm2','dPhiPeakPIchan_rm2','ampPeakPIchanEff_Jybm','dAmpPeakPIchan_Jybm',\n",
    "                           'phiPeakPIfit_rm2','dPhiPeakPIfit_rm2','ampPeakPIfitEff_Jybm','dAmpPeakPIfit_Jybm','Ifreq0_mJybm',\n",
    "                            'freq0_Hz','polAngle0Fit_deg','dPolAngle0Chan_deg','dPolAngle0Fit_deg','sigmaAddQ','sigmaAddU','dSigmaAddQ','dSigmaAddU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_sources):\n",
    "#(freqArr_Hz, IArr_Jy, QArr_Jy, UArr_Jy, dIArr_Jy, dQArr_Jy, dUArr_Jy) = data\n",
    "    input_data=(freq_array,I_arr[i],Q_arr[i],U_arr[i],dI_arr,dQ_arr,dU_arr)\n",
    "\n",
    "    mDict=run_rmsynth(input_data,  phiMax_radm2=2000, dPhi_radm2=0.25, \n",
    "                nSamples=10.0, weightType=\"variance\", fitRMSF=False,\n",
    "                noStokesI=False, phiNoise_radm2=1e6, nBits=32, showPlots=False,\n",
    "                  debug=False, verbose=False)\n",
    "    catalog_output[i]['ID']=i\n",
    "    for j in range(1,16):\n",
    "        catalog_output[i][catalog_output.dtype.names[j]]=mDict[catalog_output.dtype.names[j]]\n",
    "    try:\n",
    "        catalog_output[i]['dSigmaAddQ']=(mDict['dSigmaAddMinusQ']+mDict['dSigmaAddPlusQ'])/2.\n",
    "        catalog_output[i]['dSigmaAddU']=(mDict['dSigmaAddMinusU']+mDict['dSigmaAddPlusU'])/2.\n",
    "    except:\n",
    "        pass\n",
    "    if i%10 == 0:\n",
    "        print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1k_sim_dp0.25_rmsf22_nchan1101.npy',(catalog_output,RM_arr,angle_arr,PI_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dPhiarr=np.array([0.25,1,2,5])\n",
    "poptarr=np.zeros((4,2))\n",
    "perrarr=np.zeros_like(poptarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(catalog_output,RM_arr,angle_arr,PI_arr)=np.load('1k_sim_dp5_rmsf22_nchan1101.npy')\n",
    "catalog_output=np.array([x for x in catalog_output ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbins=30\n",
    "correction=1.10 #Correction factor on classical error.\n",
    "xbins=np.logspace(0,3,Nbins+1)\n",
    "xbin_centers=(xbins[:-1]+xbins[1:])/2.\n",
    "std_residual=np.zeros(Nbins)\n",
    "std_residual_error=np.zeros(Nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in range(Nbins):\n",
    "    srcs=np.where(np.logical_and(PI_arr >= xbins[i],PI_arr < xbins[i+1]))[0]\n",
    "    std_residual[i]=np.std(catalog_output[srcs,5]-RM_arr[srcs])\n",
    "    std_residual_error[i]=std_residual[i]/np.sqrt(2*srcs.size-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt,pcov=curve_fit(sigma_RM,xbin_centers,std_residual,p0=[0.015,1.15],sigma=std_residual_error,absolute_sigma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(popt)\n",
    "print(np.sqrt(np.diag(pcov)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poptarr[3]=popt\n",
    "perrarr[3]=np.sqrt(np.diag(pcov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(xbin_centers,std_residual,'ko',label='Simulation')\n",
    "plt.errorbar(xbin_centers,std_residual,yerr=std_residual_error,fmt='ko')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('S:N across band')\n",
    "plt.ylabel('Stdev. RM residual')\n",
    "plt.plot(xbin_centers,popt[1]*22.25/2./np.sqrt(1101)/xbin_centers,label='Classic formula with multiplier')\n",
    "plt.plot(xbin_centers,np.repeat(popt[0],xbin_centers.shape),label='Constant error')\n",
    "plt.plot(xbin_centers,np.sqrt((popt[1]*22.25/2./np.sqrt(1101)/xbin_centers)**2+popt[0]**2),label='Quadrature sum')\n",
    "plt.plot(xbin_centers,(popt[1]*22.25/2./np.sqrt(1101)/xbin_centers)+popt[0],'g--',label='Linear sum')\n",
    "plt.ylim([0.001,2])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poptarr[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(dPhiarr,poptarr[:,0],yerr=perrarr[:,0],fmt='ko')\n",
    "plt.xlabel('delta-Phi')\n",
    "plt.ylabel('Constant[0] or correction factor[1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it looks like things are getting more complicated... that's really annoying. I think I've had enough for now: this effect is so small that I don't think it matters; we can overcome this by slapping on an error term from the ionospheric correction (or lack thereof) which will be larger than the constant (which is ~0.02 rad/m^2). The correction factor may be a slightly more problematic effect, but it seems to be of order 10% or less, so maybe thats OK.\n",
    "\n",
    "Next question: \n",
    "\n",
    "# Errors in the amplitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(catalog_output,RM_arr,angle_arr,PI_arr)=np.load('50k_sim.npy')\n",
    "catalog_output=np.array([x for x in catalog_output ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_bin1=(PI_arr < 0.01)\n",
    "print('Bin 1 = {:} sources'.format(SN_bin1.sum()))\n",
    "SN_bin2=np.logical_and(PI_arr >= 0.01, PI_arr < 0.1)\n",
    "print('Bin 2 = {:} sources'.format(SN_bin2.sum()))\n",
    "SN_bin3=np.logical_and(PI_arr >= 0.1, PI_arr < 1.)\n",
    "print('Bin 3 = {:} sources'.format(SN_bin3.sum()))\n",
    "SN_bin4=np.logical_and(PI_arr >= 1., PI_arr < 10.)\n",
    "print('Bin 4 = {:} sources'.format(SN_bin4.sum()))\n",
    "SN_bin5=np.logical_and(PI_arr >= 10., PI_arr < 100.)\n",
    "print('Bin 5 = {:} sources'.format(SN_bin5.sum()))\n",
    "SN_bin6=PI_arr >= 100.\n",
    "print('Bin 6 = {:} sources'.format(SN_bin6.sum()))\n",
    "SN_threshold=(PI_arr > 0.3)  #This is the threshold for no false peak detections, based on a plot below.\n",
    "print(SN_threshold.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold,7],'ko',label='Measured (fit) amplitude')\n",
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold,3]*5,'ro',label='Measured (chan) amplitude (offset x5)')\n",
    "plt.xlabel('Input Polarized Intensity (=S:N per channel)')\n",
    "plt.ylabel('Measured polarized intensity')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.logspace(-1,3,50),'b-',label='1:1 for fit')\n",
    "plt.plot(np.logspace(-1,3,50),np.logspace(-1,3,50)*5,'g-',label='1:1 for chan (accounting for offset)')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()\n",
    "#plt.savefig('PI_figure1.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agreement looks good across the S:N range. Fit values have a band of constant thickness, suggesting fractional error is constant? It's also thicker than the channel amplitude, for all but the lowest S:N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold,7]/PI_arr[SN_threshold],'ko',label='Measured (fit)/Actual flux')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Ratio of measured to actual flux')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.ones(50),'b-',label='1')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,bins,patches=plt.hist((catalog_output[SN_threshold,7]/PI_arr[SN_threshold]),bins=50,label='Measured')\n",
    "bin_centers=(bins[:-1]+bins[1:])/2.\n",
    "xlim=plt.gca().get_xlim()\n",
    "xarr=np.linspace(*xlim,100)\n",
    "from scipy.special import erf\n",
    "yarr=np.diff(erf(bins/np.sqrt(2)))*np.sum(values)/2.\n",
    "#plt.plot(xarr,np.sum(values)/np.sqrt(2*np.pi)*np.exp((xarr)**2/(-2.)),'k-')\n",
    "#plt.plot(bin_centers,yarr,'ko-',label='Ideal')  #Predicted bin contents\n",
    "plt.legend()\n",
    "plt.title('Distribution of channel flux residuals (fit-error-normalized)')\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold,3]/PI_arr[SN_threshold],'ko',label='Measured (chan)/Actual flux')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Ratio of measured to actual flux')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.ones(50),'b-',label='1')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold,8],'ko',label='Flux error (fit)')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Flux error')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.plot(np.logspace(-1,3,50),np.ones(50),'b-',label='1')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit flux error is a constant, presumably a multiple of the noise in the RM spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold,4],'ko',label='Flux error (chan)')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Flux error')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.plot(np.logspace(-1,3,50),np.ones(50),'b-',label='1')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The channel value for the y-error is also constant, and is equal to the band-averaged S:N (as expected?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unexpectedly, the channel flux measurements are actually less prone to errors? While the fitted values tend to have a fractional uncertainty of something like 10%, the chan flux values have about the same errors at low flux, and much lower fractional errors at higher S:N levels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold,3]-PI_arr[SN_threshold],'ko',label='Measured (chan)-Actual flux')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Difference measured to actual flux')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.zeros(50),'b-',label='No difference')\n",
    "plt.plot(np.logspace(-1,3,50),np.ones(50)*2./np.sqrt(1101),'g-',label='$\\pm2\\sigma_{FDF}$')\n",
    "plt.plot(np.logspace(-1,3,50),np.ones(50)*-2./np.sqrt(1101),'g-')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()\n",
    "plt.savefig('PI_measured_diff.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],np.abs(catalog_output[SN_threshold,7]-PI_arr[SN_threshold]),'ko',label='Measured (fit)-Actual flux')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Difference measured to actual flux')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.ones(50)*2./np.sqrt(1101),'g-',label='2$\\sigma_{FDF}$')\n",
    "plt.plot(np.logspace(-1,3,50),np.logspace(-1,3,50)*0.1,'r--',label='10% of PI')\n",
    "#plt.plot(np.logspace(-1,3,50),np.zeros(50),'b-',label='1')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()\n",
    "plt.savefig('PI_fit_diff.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very bizarre. The fit produces flux values that have a consistent fractional error, which means the flux errors for high S:N objects are huge! It's pretty consistently ~<10%, but why? I don't know, but there doesn't seem to be any value in it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNcut=np.logical_and(PI_arr >= 0.3, PI_arr < 10.)\n",
    "print('Bin 5 = {:} sources'.format(SNcut.sum()))\n",
    "\n",
    "x=np.linspace(-5,5,51)\n",
    "values,bins,patches=plt.hist(((catalog_output[SNcut,3]-PI_arr[SNcut])/catalog_output[SNcut,4]).astype('float'),bins=x,label='Measured')\n",
    "bin_centers=(bins[:-1]+bins[1:])/2.\n",
    "xlim=plt.gca().get_xlim()\n",
    "xarr=np.linspace(*xlim,100)\n",
    "from scipy.special import erf\n",
    "yarr=np.diff(erf(bins/np.sqrt(2)))*np.sum(values)/2.\n",
    "#plt.plot(xarr,np.sum(values)/np.sqrt(2*np.pi)*np.exp((xarr)**2/(-2.)),'k-')\n",
    "plt.plot(bin_centers,yarr,'ko-',label='Ideal')  #Predicted bin contents\n",
    "plt.legend()\n",
    "plt.title('Distribution of channel flux residuals (channel-error-normalized)')\n",
    "#plt.xlabel('(PI$_{chan}$ - PI$_{sim}$)/$\\sigma_{PI,chan}$')\n",
    "#plt.yscale('log')\n",
    "plt.savefig('PI_histogram.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like in this regime the flux errors are very good. At the very highest S:N, it tends to underestimate the flux slightly. But that's beyond S:N_chan ~100, or band-averaged S:N~3000, so it's not a real problem.  It's certainly going to be the case that other forms of systematic errors are more significant.\n",
    "\n",
    "There may be hints of a slight bias towards negative values, meaning the flux is underestimated. This could be due to the peak location being between sampling points in FD. In principle, the fit is supposed to capture this, but it introduces such large errors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "For RM errors:\n",
    "-  the fit and channel errors follow the same formula, with a scaling difference of ~3.4.  \n",
    "-  the channel FDs are strongly affected by quantization, with error introduced at the level of the quantization scale.  \n",
    "-  the fit FDs are good, and have a Gaussian distribution centered on zero.\n",
    "-  the width of the fit error distribution is described by the channel uncertainties, not the fit uncertainties.\n",
    "-  the ideal quantities to report at the fit FD, and the channel uncertainties. This combination produces a Gaussian distribution of unit width (i.e. perfect uncertainties).\n",
    "\n",
    "For polarized intensity:\n",
    "-  the channel uncertainty is equal to the band-averaged S:N. The fit uncertainty is a fraction of that (~1/3).\n",
    "-  the error in the channel PI is Gaussian, with width equal to the channel uncertainty\n",
    "-  the error in the fit PI is a fraction of the PI; i.e. there is some fractional uncertainty, of order a few percent. Thus, bright sources have high (absolute) flux errors, while fainter sources aren't really affected.\n",
    "-  the channel PI errors are fairly Gaussian distributed, with width equal to the channel uncertanties, but there are hints that it might be biased slightly low, probably due to missing the true peak between the FD planes.\n",
    "-  the ideal quantities to report are slightly uncertain: the channel values have more reliabable errors, partiularly at higher S:N, while the fit values (maybe?) don't have the bias but have worse errors (and no good uncertainties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow up:\n",
    "\n",
    "Jennifer suggested that maybe reducing the oversampling in the RM spectrum might affect the error properties, particularly for the amplitude.\n",
    "\n",
    "Let's try reducing the oversampling to ~3-4, to see what that does. The previous sim was using dphi=1, for RMWF FWHM=22.25, so lets try dphi=5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation inputs:\n",
    "num_sources=100000  #number of sources to simulate\n",
    "Q_arr=np.zeros([num_sources,freq_array.size])\n",
    "U_arr=np.zeros_like(Q_arr)\n",
    "I_arr=np.ones_like(Q_arr)\n",
    "dQ_arr=np.ones(freq_array.size)\n",
    "dU_arr=np.ones_like(dQ_arr)\n",
    "dI_arr=np.ones_like(dQ_arr)\n",
    "RM_arr=np.random.uniform(-1000,1000,num_sources)\n",
    "angle_arr=np.random.uniform(0,180,num_sources)\n",
    "PI_arr=10**np.random.uniform(-3,3,num_sources)\n",
    "\n",
    "sim_perfect=Faraday_thin_complex_polarization(freq_array,RM_arr,PI_arr,angle_arr)\n",
    "Q_arr=np.real(sim_perfect)+np.random.normal(size=Q_arr.shape)\n",
    "U_arr=np.imag(sim_perfect)+np.random.normal(size=Q_arr.shape)\n",
    "\n",
    "catalog_output=np.zeros(num_sources,dtype='f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8')\n",
    "catalog_output.dtype.names=('ID','phiPeakPIchan_rm2','dPhiPeakPIchan_rm2','ampPeakPIchanEff_Jybm','dAmpPeakPIchan_Jybm',\n",
    "                           'phiPeakPIfit_rm2','dPhiPeakPIfit_rm2','ampPeakPIfitEff_Jybm','dAmpPeakPIfit_Jybm','Ifreq0_mJybm',\n",
    "                            'freq0_Hz','polAngle0Fit_deg','dPolAngle0Chan_deg','dPolAngle0Fit_deg','sigmaAddQ','sigmaAddU','dSigmaAddQ','dSigmaAddU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_sources):\n",
    "#(freqArr_Hz, IArr_Jy, QArr_Jy, UArr_Jy, dIArr_Jy, dQArr_Jy, dUArr_Jy) = data\n",
    "    input_data=(freq_array,I_arr[i],Q_arr[i],U_arr[i],dI_arr,dQ_arr,dU_arr)\n",
    "\n",
    "    mDict=run_rmsynth(input_data,  phiMax_radm2=2000, dPhi_radm2=5., \n",
    "                nSamples=10.0, weightType=\"variance\", fitRMSF=False,\n",
    "                noStokesI=False, phiNoise_radm2=1e6, nBits=32, showPlots=False,\n",
    "                  debug=False, verbose=False)\n",
    "    catalog_output[i]['ID']=i\n",
    "    for j in range(1,16):\n",
    "        catalog_output[i][catalog_output.dtype.names[j]]=mDict[catalog_output.dtype.names[j]]\n",
    "    try:\n",
    "        catalog_output[i]['dSigmaAddQ']=(mDict['dSigmaAddMinusQ']+mDict['dSigmaAddPlusQ'])/2.\n",
    "        catalog_output[i]['dSigmaAddU']=(mDict['dSigmaAddMinusU']+mDict['dSigmaAddPlusU'])/2.\n",
    "    except:\n",
    "        pass\n",
    "    if i%10 == 0:\n",
    "        print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('100k_sim_dphi5.npy',(catalog_output,RM_arr,angle_arr,PI_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(catalog_output,RM_arr,angle_arr,PI_arr)=np.load('100k_sim_dphi5.npy')\n",
    "catalog_output=np.array([x for x in catalog_output ])\n",
    "RM_arr=RM_arr.astype('float')\n",
    "angle_arr=angle_arr.astype('float')\n",
    "PI_arr=PI_arr.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_threshold=(PI_arr > 0.3)  #This is the threshold for no false peak detections, based on a plot below.\n",
    "print(SN_threshold.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold,7]/PI_arr[SN_threshold],'ko',label='Measured (fit)/Actual flux')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Ratio of measured to actual flux')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.ones(50),'b-',label='1')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with the previous plot, these data have a much tighter distribution in the ratio, nearly entirely within a few percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold,3]-PI_arr[SN_threshold],'ko',label='Measured (chan)-Actual flux')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Difference measured to actual flux')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.zeros(50),'b-',label='0')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],(catalog_output[SN_threshold,3]-PI_arr[SN_threshold])/PI_arr[SN_threshold],'ko',label='(Measured (chan)-Actual flux)/Actual')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Fractional difference measured to actual flux ()')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.zeros(50),'b-',label='0')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],(catalog_output[SN_threshold,7]-PI_arr[SN_threshold])/PI_arr[SN_threshold],'ko',label='Fractional Measured (fit)-Actual flux')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Fractional Difference measured to actual flux')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.zeros(50),'b-',label='0')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think these last two plots are informative: the channel values tend to fit ~2-3% too low, but the fit values have fractional errors of ~5%, both in the high S:N regime. In the lower S:N regime, S:N_band <~30, the errors increase slightly in both cases.\n",
    "\n",
    "### Comparing against reported uncertainties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],(catalog_output[SN_threshold,3]-PI_arr[SN_threshold])/catalog_output[SN_threshold,4],'ko',label='(Measured (chan)-Actual flux)/Uncertainty')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Normalized residual')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.zeros(50),'b-',label='0')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()\n",
    "plt.ylim([-100,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the channel versions, the error is flat at high S:N but the (absolute) bias increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PI_arr[SN_threshold],(catalog_output[SN_threshold,7]-PI_arr[SN_threshold])/catalog_output[SN_threshold,4],'ko',label='(Measured (chan)-Actual flux)/Uncertainty')\n",
    "plt.xlabel('Polarized Intensity (S:N per channel)')\n",
    "plt.ylabel('Normalized residual')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(np.logspace(-1,3,50),np.zeros(50),'b-',label='0')\n",
    "#plt.plot(np.logspace(-1,3,50),0.33/np.logspace(-1,3,50),label='FWHM/(2*S:N)')\n",
    "#plt.plot(PI_arr[SN_threshold],catalog_output[SN_threshold]['dPhiPeakPIfit_rm2'],'go',label='fit_error')\n",
    "plt.legend()\n",
    "plt.ylim([-100,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the channel version, the increased fractional error, compared to fixed uncertainty, leads to large errors at high S:N. For S:N_band <~100 it doesn't matter much, but becomes a bigger issue for larger S:N.\n",
    "\n",
    "## Conclusions:\n",
    "The channel PI introduces a small bias that slightly underestimates the flux, statistically. This will depend on how oversampled the FWHM is; higher oversampling reduces the amount of difference between the FD of the peak and the nearest sampling point, reducing the flux error. The bias can probably be accounted for with a statistical correction, but this correction will have to be determined for the RMSF and oversampling specific to the data.\n",
    "\n",
    "The fit PI continues to show higher fractional errors, although these seem to be less with the lower oversampling. There may be something wrong with the fitting procedure, but this would require careful investigation in the fitting code.\n",
    "\n",
    "It's not clear which would be better to use. If we use the fit, we might need to tack on some fractional uncertainty term to be accurate. If we use the channel, we might need to correct for the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
